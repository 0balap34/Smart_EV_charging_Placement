{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cbc5a5f5-72c5-4b63-80c6-37a5f744472a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== London OCM Integration (fixed) ===\n",
      "OCM rows in:       10,000\n",
      "Stations out:      10,000\n",
      "Borough 'Unknown': 9,019\n",
      "UK mean util %:    50.22\n",
      "UK mean energy kWh:36.88\n",
      "Density mean used: 9318.95 people/km²\n",
      "Saved: uk_stations_enriched.csv\n",
      "\n",
      "Preview:\n",
      "   ocm_id            operator                                  usage_type  \\\n",
      "0  253415              EV Dot                    Public - Pay At Location   \n",
      "1    4396  (Unknown Operator)                                         nan   \n",
      "2   52877       BP Pulse (UK)                Public - Membership Required   \n",
      "3  146490               VIRTA  Private - For Staff, Visitors or Customers   \n",
      "4    4399       BP Pulse (UK)                Public - Membership Required   \n",
      "\n",
      "        status is_operational         address1             address2  \\\n",
      "0          nan            nan   Rainsford Road                  nan   \n",
      "1  Operational           True    Spring Garden          Westminster   \n",
      "2  Operational           True   Spring Gardens  City of Westminster   \n",
      "3  Operational           True       440 Strand        Covent Garden   \n",
      "4  Operational           True  Whitcomb Street          Westminster   \n",
      "\n",
      "         town state_province  postcode  ...      borough  borough_density_km2  \\\n",
      "0  Chelmsford            nan   CM1 2XB  ...      Unknown          9318.948649   \n",
      "1      London            nan  SW1A 2BN  ...  Westminster         13608.400000   \n",
      "2      London            nan  SW1A 2TS  ...  Westminster         13608.400000   \n",
      "3      London            nan  WC2R 0QS  ...      Unknown          9318.948649   \n",
      "4      London            nan  WC2H 7DT  ...  Westminster         13608.400000   \n",
      "\n",
      "   uk_avg_util_pct uk_avg_energy_kWh  uk_usage_rows priority_score  \\\n",
      "0        50.216667         36.881026             78       0.131437   \n",
      "1        50.216667         36.881026             78       0.209204   \n",
      "2        50.216667         36.881026             78       0.221010   \n",
      "3        50.216667         36.881026             78       0.131437   \n",
      "4        50.216667         36.881026             78       0.212507   \n",
      "\n",
      "     last_status_update         last_verified       submission_status  \\\n",
      "0  2023-05-04T08:44:00Z  2023-05-04T08:44:00Z  Imported and Published   \n",
      "1  2011-05-17T17:23:00Z  2011-05-17T17:23:00Z    Submission Published   \n",
      "2  2023-04-03T16:58:00Z  2023-04-03T16:58:00Z    Submission Published   \n",
      "3  2020-01-10T10:18:00Z  2020-01-10T10:18:00Z    Submission Published   \n",
      "4  2023-04-03T17:00:00Z  2023-04-03T17:00:00Z    Submission Published   \n",
      "\n",
      "                       data_provider  \n",
      "0  UK National Charge Point Registry  \n",
      "1       Open Charge Map Contributors  \n",
      "2       Open Charge Map Contributors  \n",
      "3       Open Charge Map Contributors  \n",
      "4       Open Charge Map Contributors  \n",
      "\n",
      "[5 rows x 29 columns]\n"
     ]
    }
   ],
   "source": [
    "# ===============================================\n",
    "# 01_integrate_london_ocm.py  (fixed)\n",
    "# Integrate OpenChargeMap (London) + global usage + borough density\n",
    "# Outputs: uk_stations_enriched.csv\n",
    "# No sklearn; robust to missing/constant/empty data.\n",
    "# ===============================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "# --------- File paths ----------\n",
    "ocm_path   = Path(\"london_ev_chargepoints_openchargemap.csv\")\n",
    "usage_path = Path(\"Global_EV_Charging_Behavior_2024.csv\")\n",
    "pop_path   = Path(\"housing-density-borough.csv\")\n",
    "out_csv    = Path(\"uk_stations_enriched.csv\")\n",
    "\n",
    "# --------- Helpers ----------\n",
    "def read_csv_smart(p: Path) -> pd.DataFrame:\n",
    "    for enc in (\"utf-8\", \"utf-8-sig\", \"cp1252\"):\n",
    "        try:\n",
    "            return pd.read_csv(p, encoding=enc)\n",
    "        except Exception:\n",
    "            pass\n",
    "    return pd.read_csv(p)\n",
    "\n",
    "def pick(df: pd.DataFrame, candidates, required=False):\n",
    "    \"\"\"Pick first matching column (case/contains-insensitive).\"\"\"\n",
    "    cmap = {str(c).lower().strip(): c for c in df.columns}\n",
    "    for want in candidates:\n",
    "        key = want.lower().strip()\n",
    "        if key in cmap:\n",
    "            return cmap[key]\n",
    "        for have_l, have in cmap.items():\n",
    "            if key in have_l:\n",
    "                return have\n",
    "    if required:\n",
    "        raise KeyError(f\"Missing columns {candidates}. Available: {list(df.columns)}\")\n",
    "    return None\n",
    "\n",
    "def to_num(s): return pd.to_numeric(s, errors=\"coerce\")\n",
    "\n",
    "def minmax(series: pd.Series) -> pd.Series:\n",
    "    s = pd.to_numeric(series, errors=\"coerce\").astype(float)\n",
    "    if s.size == 0: return s\n",
    "    m, M = s.min(skipna=True), s.max(skipna=True)\n",
    "    if (pd.isna(m) and pd.isna(M)) or M == m:\n",
    "        return pd.Series(0.0, index=s.index)\n",
    "    return (s - m) / (M - m)\n",
    "\n",
    "def minmax_df(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    if df.shape[0] == 0: return df.copy()\n",
    "    out = pd.DataFrame(index=df.index)\n",
    "    for c in df.columns: out[c] = minmax(df[c])\n",
    "    return out\n",
    "\n",
    "# --------- 1) Read ----------\n",
    "ocm   = read_csv_smart(ocm_path)\n",
    "usage = read_csv_smart(usage_path)\n",
    "pop   = read_csv_smart(pop_path)\n",
    "\n",
    "# FIX: use .str.strip() (vectorized), not .strip()\n",
    "for df in (ocm, usage, pop):\n",
    "    for c in df.select_dtypes(include=\"object\"):\n",
    "        df[c] = df[c].astype(str).str.strip()\n",
    "\n",
    "# --------- 2) OCM columns ----------\n",
    "COL_ID   = pick(ocm, [\"OCM_ID\",\"id\"], required=True)\n",
    "COL_OP   = pick(ocm, [\"OperatorA\",\"Operator\",\"Network\"])\n",
    "COL_WEB  = pick(ocm, [\"OperatorWebsite\",\"Website\"])\n",
    "COL_USE  = pick(ocm, [\"UsageType\"])\n",
    "COL_STAT = pick(ocm, [\"Status\"])\n",
    "COL_ISOP = pick(ocm, [\"IsOperational\"])\n",
    "COL_A1   = pick(ocm, [\"AddressLine1\"])\n",
    "COL_A2   = pick(ocm, [\"AddressLine2\"])\n",
    "COL_TOWN = pick(ocm, [\"Town\",\"City\"])\n",
    "COL_PROV = pick(ocm, [\"StateOrProvince\",\"County\",\"Region\"])\n",
    "COL_PC   = pick(ocm, [\"Postcode\",\"Post code\",\"Postal Code\"])\n",
    "COL_CTRY = pick(ocm, [\"Country\"])\n",
    "COL_LAT  = pick(ocm, [\"Latitude\",\"Lat\"], required=True)\n",
    "COL_LON  = pick(ocm, [\"Longitude\",\"Lon\",\"Long\"], required=True)\n",
    "COL_TITLE= pick(ocm, [\"Title\",\"Site Name\"])\n",
    "COL_NPTS = pick(ocm, [\"NumberOfPoints\",\"Number Of Points\"])\n",
    "COL_CONN = pick(ocm, [\"ConnectorTypes\"])\n",
    "COL_MAXK = pick(ocm, [\"MaxPowerKW\",\"Max Power KW\"])\n",
    "COL_ALLK = pick(ocm, [\"AllConnectorPowersKW\",\"All Connector Powers KW\"])\n",
    "COL_CSTAT= pick(ocm, [\"ConnectionStatuses\"])\n",
    "COL_DP   = pick(ocm, [\"DataProvider\"])\n",
    "COL_UPD  = pick(ocm, [\"DateLastStatusUpdate\"])\n",
    "COL_VER  = pick(ocm, [\"DateLastVerified\"])\n",
    "COL_SUB  = pick(ocm, [\"SubmissionStatus\"])\n",
    "\n",
    "# Numerics\n",
    "ocm[COL_LAT] = to_num(ocm[COL_LAT])\n",
    "ocm[COL_LON] = to_num(ocm[COL_LON])\n",
    "if COL_MAXK: ocm[COL_MAXK] = to_num(ocm[COL_MAXK])\n",
    "if COL_NPTS: ocm[COL_NPTS] = to_num(ocm[COL_NPTS])\n",
    "\n",
    "# --------- 3) UK usage means ----------\n",
    "COL_COUNTRY_U = pick(usage, [\"Country\"])\n",
    "COL_UTIL_U    = pick(usage, [\"Station Utilization Rate (%)\",\"Utilization Rate (%)\",\"Utilisation Rate (%)\"])\n",
    "COL_ENERGY_U  = pick(usage, [\"Energy Delivered (kWh)\",\"Energy (kWh)\",\"kWh\"])\n",
    "\n",
    "if COL_COUNTRY_U:\n",
    "    mask = usage[COL_COUNTRY_U].str.lower().isin(\n",
    "        [\"united kingdom\",\"uk\",\"england\",\"scotland\",\"wales\",\"northern ireland\"]\n",
    "    )\n",
    "    usage_uk = usage[mask]\n",
    "else:\n",
    "    usage_uk = pd.DataFrame(columns=usage.columns)\n",
    "\n",
    "if usage_uk.empty: usage_uk = usage.copy()\n",
    "\n",
    "uk_avg_util   = float(usage_uk[COL_UTIL_U].mean(skipna=True))   if COL_UTIL_U in usage_uk else 0.0\n",
    "uk_avg_energy = float(usage_uk[COL_ENERGY_U].mean(skipna=True)) if COL_ENERGY_U in usage_uk else 0.0\n",
    "uk_n_rows     = int(usage_uk.shape[0])\n",
    "if np.isnan(uk_avg_util):   uk_avg_util = 0.0\n",
    "if np.isnan(uk_avg_energy): uk_avg_energy = 0.0\n",
    "\n",
    "# --------- 4) Borough density (latest year) ----------\n",
    "COL_BORO_P = pick(pop, [\"Name\",\"Borough\"], required=True)\n",
    "COL_YEAR_P = pick(pop, [\"Year\"])\n",
    "COL_DENS_P = pick(pop, [\"Population_per_square_kilometre\",\"Population per square kilometre\",\"Density\"], required=True)\n",
    "\n",
    "pop[COL_DENS_P] = to_num(pop[COL_DENS_P].astype(str).str.replace(\",\", \"\", regex=False))\n",
    "if COL_YEAR_P: pop[COL_YEAR_P] = to_num(pop[COL_YEAR_P])\n",
    "\n",
    "if COL_YEAR_P:\n",
    "    pop_latest = pop.sort_values(COL_YEAR_P).groupby(COL_BORO_P, as_index=False).tail(1)\n",
    "else:\n",
    "    pop_latest = pop.drop_duplicates(subset=[COL_BORO_P], keep=\"last\")\n",
    "\n",
    "pop_latest.rename(columns={COL_BORO_P:\"borough_name\", COL_DENS_P:\"borough_density_km2\"}, inplace=True)\n",
    "pop_latest[\"borough_key\"] = pop_latest[\"borough_name\"].str.lower()\n",
    "\n",
    "# --------- 5) Extract London borough from text ----------\n",
    "LONDON_BOROUGHS = [\n",
    "    \"City of London\",\"Barking and Dagenham\",\"Barnet\",\"Bexley\",\"Brent\",\"Bromley\",\"Camden\",\"Croydon\",\n",
    "    \"Ealing\",\"Enfield\",\"Greenwich\",\"Hackney\",\"Hammersmith and Fulham\",\"Haringey\",\"Harrow\",\"Havering\",\n",
    "    \"Hillingdon\",\"Hounslow\",\"Islington\",\"Kensington and Chelsea\",\"Kingston upon Thames\",\"Lambeth\",\n",
    "    \"Lewisham\",\"Merton\",\"Newham\",\"Redbridge\",\"Richmond upon Thames\",\"Southwark\",\"Sutton\",\n",
    "    \"Tower Hamlets\",\"Waltham Forest\",\"Wandsworth\",\"Westminster\"\n",
    "]\n",
    "ALIASES = {\n",
    "    \"city of westminster\":\"Westminster\",\n",
    "    \"hammersmith & fulham\":\"Hammersmith and Fulham\",\n",
    "    \"kensington & chelsea\":\"Kensington and Chelsea\",\n",
    "    \"richmond upon thames\":\"Richmond upon Thames\",\n",
    "    \"kingston upon thames\":\"Kingston upon Thames\",\n",
    "}\n",
    "\n",
    "boro_patterns = [(b, re.compile(rf\"\\b{re.escape(b)}\\b\", re.I)) for b in LONDON_BOROUGHS]\n",
    "alias_patterns = [(ALIASES[k], re.compile(rf\"\\b{k}\\b\", re.I)) for k in ALIASES]\n",
    "\n",
    "def extract_borough(row) -> str:\n",
    "    fields = []\n",
    "    for c in [COL_A1, COL_A2, COL_TITLE, COL_TOWN, COL_PROV]:\n",
    "        if c and c in row and pd.notna(row[c]):\n",
    "            fields.append(str(row[c]))\n",
    "    text = \" | \".join(fields).lower()\n",
    "    for b, pat in boro_patterns:\n",
    "        if pat.search(text): return b\n",
    "    for b, pat in alias_patterns:\n",
    "        if pat.search(text): return b\n",
    "    return \"Unknown\"\n",
    "\n",
    "ocm[\"borough\"] = ocm.apply(extract_borough, axis=1)\n",
    "\n",
    "# --------- 6) Shape station table ----------\n",
    "stations = pd.DataFrame({\n",
    "    \"ocm_id\": ocm[COL_ID],\n",
    "    \"operator\": ocm[COL_OP] if COL_OP else np.nan,\n",
    "    \"usage_type\": ocm[COL_USE] if COL_USE else np.nan,\n",
    "    \"status\": ocm[COL_STAT] if COL_STAT else np.nan,\n",
    "    \"is_operational\": ocm[COL_ISOP] if COL_ISOP else np.nan,\n",
    "    \"address1\": ocm[COL_A1] if COL_A1 else np.nan,\n",
    "    \"address2\": ocm[COL_A2] if COL_A2 else np.nan,\n",
    "    \"town\": ocm[COL_TOWN] if COL_TOWN else np.nan,\n",
    "    \"state_province\": ocm[COL_PROV] if COL_PROV else np.nan,\n",
    "    \"postcode\": ocm[COL_PC] if COL_PC else np.nan,\n",
    "    \"country\": ocm[COL_CTRY] if COL_CTRY else np.nan,\n",
    "    \"latitude\": ocm[COL_LAT],\n",
    "    \"longitude\": ocm[COL_LON],\n",
    "    \"title\": ocm[COL_TITLE] if COL_TITLE else np.nan,\n",
    "    \"num_points\": ocm[COL_NPTS] if COL_NPTS else np.nan,\n",
    "    \"connector_types\": ocm[COL_CONN] if COL_CONN else np.nan,\n",
    "    \"max_power_kw\": ocm[COL_MAXK] if COL_MAXK else np.nan,\n",
    "    \"all_connector_powers_kw\": ocm[COL_ALLK] if COL_ALLK else np.nan,\n",
    "    \"connection_statuses\": ocm[COL_CSTAT] if COL_CSTAT else np.nan,\n",
    "    \"data_provider\": ocm[COL_DP] if COL_DP else np.nan,\n",
    "    \"last_status_update\": ocm[COL_UPD] if COL_UPD else np.nan,\n",
    "    \"last_verified\": ocm[COL_VER] if COL_VER else np.nan,\n",
    "    \"submission_status\": ocm[COL_SUB] if COL_SUB else np.nan,\n",
    "    \"borough\": ocm[\"borough\"]\n",
    "})\n",
    "\n",
    "# --------- 7) Merge borough density ----------\n",
    "stations[\"borough_key\"] = stations[\"borough\"].astype(str).str.strip().str.lower()\n",
    "stations = stations.merge(pop_latest[[\"borough_key\",\"borough_density_km2\"]],\n",
    "                          on=\"borough_key\", how=\"left\")\n",
    "\n",
    "density_mean = float(pop_latest[\"borough_density_km2\"].mean(skipna=True))\n",
    "stations[\"borough_density_km2\"] = stations[\"borough_density_km2\"].fillna(density_mean)\n",
    "\n",
    "# --------- 8) Attach UK usage means ----------\n",
    "stations[\"uk_avg_util_pct\"]   = uk_avg_util\n",
    "stations[\"uk_avg_energy_kWh\"] = uk_avg_energy\n",
    "stations[\"uk_usage_rows\"]     = uk_n_rows\n",
    "\n",
    "# --------- 9) Features & score ----------\n",
    "feat = pd.DataFrame({\n",
    "    \"util\": stations[\"uk_avg_util_pct\"],\n",
    "    \"density\": stations[\"borough_density_km2\"],\n",
    "    \"power\": stations[\"max_power_kw\"],\n",
    "    \"points\": stations[\"num_points\"]\n",
    "})\n",
    "feat = feat.fillna(feat.median(numeric_only=True))\n",
    "feat_scaled = minmax_df(feat).fillna(0.0)\n",
    "\n",
    "stations[\"priority_score\"] = (\n",
    "    0.35 * feat_scaled[\"density\"] +\n",
    "    0.30 * feat_scaled[\"power\"] +\n",
    "    0.25 * feat_scaled[\"util\"] +\n",
    "    0.10 * feat_scaled[\"points\"]\n",
    ").fillna(0.0)\n",
    "\n",
    "# --------- 10) Save ----------\n",
    "keep_cols = [\n",
    "    \"ocm_id\",\"operator\",\"usage_type\",\"status\",\"is_operational\",\n",
    "    \"address1\",\"address2\",\"town\",\"state_province\",\"postcode\",\"country\",\n",
    "    \"latitude\",\"longitude\",\"title\",\"num_points\",\"connector_types\",\n",
    "    \"max_power_kw\",\"all_connector_powers_kw\",\"connection_statuses\",\n",
    "    \"borough\",\"borough_density_km2\",\n",
    "    \"uk_avg_util_pct\",\"uk_avg_energy_kWh\",\"uk_usage_rows\",\n",
    "    \"priority_score\",\"last_status_update\",\"last_verified\",\n",
    "    \"submission_status\",\"data_provider\"\n",
    "]\n",
    "stations[keep_cols].to_csv(out_csv, index=False)\n",
    "\n",
    "# --------- 11) Summary ----------\n",
    "print(\"\\n=== London OCM Integration (fixed) ===\")\n",
    "print(f\"OCM rows in:       {len(ocm):,}\")\n",
    "print(f\"Stations out:      {len(stations):,}\")\n",
    "print(f\"Borough 'Unknown': {(stations['borough'] == 'Unknown').sum():,}\")\n",
    "print(f\"UK mean util %:    {uk_avg_util:.2f}\")\n",
    "print(f\"UK mean energy kWh:{uk_avg_energy:.2f}\")\n",
    "print(f\"Density mean used: {density_mean:.2f} people/km²\")\n",
    "print(\"Saved:\", out_csv)\n",
    "print(\"\\nPreview:\")\n",
    "print(stations[keep_cols].head(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dfac938-87b6-47f5-b5aa-38e2b51ed779",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38360f7f-adc7-45dd-a006-a40da64b47fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dfdf899-331c-4e82-a74f-cae4a71f6cac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
